{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COVID-19 Predictions with ARIMA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd \n",
    "import random\n",
    "import math\n",
    "import time\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import operator \n",
    "from pmdarima.arima import auto_arima\n",
    "import pmdarima as pm\n",
    "from pmdarima.model_selection import train_test_split\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.ticker as ticker\n",
    "import datetime\n",
    "from datetime import date\n",
    "import operator\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confirmed_cases_global = pd.read_csv('https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv')\n",
    "coloco = ['Lat','Long']\n",
    "confirmed_cases_global.drop(coloco, inplace=True, axis=1)\n",
    "confirmed_cases_global=confirmed_cases_global[confirmed_cases_global['Province/State']!='Recovered']\n",
    "confirmed_cases_global=confirmed_cases_global[confirmed_cases_global['Province/State']!='Diamond Princess']\n",
    "confirmed_cases_global.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a row for Canada\n",
    "confirmed_cases_Canada=confirmed_cases_global[confirmed_cases_global['Country/Region']=='Canada']\n",
    "confirmed_cases_Canada=confirmed_cases_Canada.groupby(['Country/Region']).sum().reset_index()\n",
    "confirmed_cases_Canada.insert(0, 'Province/State', float('NaN'))\n",
    "confirmed_cases_Canada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confirmed_cases_US = pd.read_csv('https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_US.csv')\n",
    "confirmed_cases_US.rename(columns={'Province_State':'Province/State', 'Country_Region':'Country/Region', 'Long_':'Long' }, inplace=True)\n",
    "coloc = ['UID', 'iso2','iso3' ,'code3', 'FIPS','Admin2','Combined_Key','Lat','Long']\n",
    "confirmed_cases_US.drop(coloc, inplace=True, axis=1)\n",
    "confirmed_cases_US.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confirmed_cases_US=confirmed_cases_US.groupby(['Province/State','Country/Region']).sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deaths_cases_global = pd.read_csv('https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv')\n",
    "colo = ['Lat','Long']\n",
    "deaths_cases_global=deaths_cases_global[deaths_cases_global['Province/State']!='Recovered']\n",
    "deaths_cases_global=deaths_cases_global[deaths_cases_global['Province/State']!='Diamond Princess']\n",
    "deaths_cases_global.drop(colo, inplace=True, axis=1)\n",
    "deaths_cases_global.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deaths_cases_Canada=deaths_cases_global[deaths_cases_global['Country/Region']=='Canada']\n",
    "deaths_cases_Canada=deaths_cases_Canada.groupby(['Country/Region']).sum().reset_index()\n",
    "deaths_cases_Canada.insert(0, 'Province/State', float('NaN'))\n",
    "deaths_cases_Canada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deaths_cases_US = pd.read_csv('https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_US.csv')\n",
    "deaths_cases_US.rename(columns={'Province_State':'Province/State', 'Country_Region':'Country/Region','Long_':'Long' }, inplace=True)\n",
    "col = ['UID', 'iso2','iso3' ,'code3', 'FIPS','Admin2','Combined_Key', 'Population','Long','Lat']\n",
    "deaths_cases_US.drop(col, inplace=True, axis=1)\n",
    "deaths_cases_US.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deaths_cases_US = deaths_cases_US.groupby(['Province/State','Country/Region']).sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confirmed_cases= pd.concat([confirmed_cases_global, confirmed_cases_US,confirmed_cases_Canada], axis=0, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deaths_cases = pd.concat([deaths_cases_global, deaths_cases_US,deaths_cases_Canada], axis=0, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recoveries_cases = pd.read_csv('https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_recovered_global.csv')\n",
    "coloco = ['Lat','Long']\n",
    "recoveries_cases.drop(coloco, inplace=True, axis=1)\n",
    "recoveries_cases.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = confirmed_cases.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colonames = recoveries_cases.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confirmed = confirmed_cases.loc[:, colnames[4]:colnames[-1]]\n",
    "deaths = deaths_cases.loc[:, colnames[4]:colnames[-1]]\n",
    "recoveries = recoveries_cases.loc[:, colonames[4]:colonames[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_date = confirmed.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_days = np.array([i for i in range(len(time_date))]).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions for days ahead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_days_ahead = 2\n",
    "#pred_days_ahead = 7\n",
    "#pred_days_ahead = 30\n",
    "predictions_ahead = np.array([i for i in range(len(time_date)+pred_days_ahead)]).reshape(-1, 1)\n",
    "\n",
    "predictions_ahead_plus_day = np.array([i for i in range(len(time_date)+pred_days_ahead+1)]).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.datetime.strptime(colnames[4], \"%m/%d/%y\")\n",
    "end = datetime.datetime.strptime(colnames[-1], \"%m/%d/%y\")\n",
    "predictions_ahead_dates = [start + datetime.timedelta(days=d) for d in range(len(predictions_ahead_plus_day))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confirmed_cases = confirmed_cases[~confirmed_cases['Country/Region'].isin(['Central African Republic','Chad'])]\n",
    "\n",
    "#confirmed_cases = confirmed_cases[confirmed_cases['Country/Region'].isin(['Canada'])]\n",
    "#confirmed_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries=confirmed_cases['Country/Region'].tolist()\n",
    "province=confirmed_cases['Province/State'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_models = dict()\n",
    "prediction_models_confirmed = {'SVR': 0}\n",
    "prediction_models_deaths = {'SVR': 0}\n",
    "prediction_models_recoveries = {'SVR': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction Models\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.svm import SVR\n",
    "def SVM_regression(train_x, train_y, test_x, test_y, X_test,subpopulation,X_train, Y_train):\n",
    "    \n",
    "    # Tune parameters to find optimal ones\n",
    "   # c = [0.01, 0.1, 1]\n",
    "   # gamma = [0.01, 0.1, 1]\n",
    "   #epsilon = [0.01, 0.1, 1]\n",
    "   #shrinking = [True, False]\n",
    "    #degree = [3, 4, 5, 6]\n",
    "  #grid_parameters = {'C': c, 'gamma' : gamma ,'epsilon': epsilon, 'shrinking' : shrinking, 'degree':degree} \n",
    "   #regressor = RandomizedSearchCV(SVR(shrinking=True, kernel='poly',gamma=0.01, epsilon=1, C=0.1), grid_parameters, scoring='neg_mean_squared_error', \n",
    "    #                               cv=5)\n",
    "    \n",
    "    if (subpopulation == 'confirmed'):\n",
    "         degree = 3\n",
    "    elif (subpopulation == 'deaths'):\n",
    "        degree = 4\n",
    "    else :\n",
    "        degree = 5\n",
    "\n",
    "\n",
    "    regressor = SVR(shrinking=True, kernel='poly',gamma=0.01, epsilon=1,degree=degree, C=0.1)\n",
    "    regressor.fit(train_x, train_y)\n",
    "    y_pred = regressor.predict(test_x)\n",
    "    \n",
    "    \n",
    "    if (subpopulation == 'confirmed'):\n",
    "         prediction_models_confirmed['SVR'] = mean_absolute_error(y_pred, test_y)\n",
    "    elif (subpopulation == 'deaths'):\n",
    "        prediction_models_deaths['SVR'] = mean_absolute_error(y_pred, test_y)\n",
    "    else :\n",
    "        prediction_models_recoveries['SVR'] = mean_absolute_error(y_pred, test_y)\n",
    "    \n",
    "    regressor.fit(X_train, Y_train)\n",
    "    predictions = regressor.predict(X_test)\n",
    "    \n",
    "    return(predictions) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "def RF_regression(train_x, train_y, test_x, test_y,X_test,subpopulation,X_train, Y_train):\n",
    "    \n",
    "    # Tune parameters to find optimal ones\n",
    "    n_estimators = [100, 150, 300]\n",
    "    grid_parameters = {'n_estimators': n_estimators}\n",
    "#    regressor = RandomizedSearchCV(RandomForestRegressor(), grid_parameters, scoring='neg_mean_squared_error', \n",
    "#                                   cv=3)\n",
    "    \n",
    "    regressor = RandomForestRegressor(n_estimators = 200, random_state = 42) \n",
    "    regressor.fit(train_x, train_y)\n",
    "    y_pred = regressor.predict(test_x)\n",
    "    \n",
    "    \n",
    "    if (subpopulation == 'confirmed'):\n",
    "         prediction_models_confirmed['Random_Forest'] = mean_absolute_error(y_pred, test_y)\n",
    "    elif (subpopulation == 'deaths'):\n",
    "        prediction_models_deaths['Random_Forest'] = mean_absolute_error(y_pred, test_y)\n",
    "    else :\n",
    "        prediction_models_recoveries['Random_Forest'] = mean_absolute_error(y_pred, test_y)\n",
    "    \n",
    "    regressor.fit(X_train, Y_train)\n",
    "    predictions = regressor.predict(X_test)\n",
    "    \n",
    "    return(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosted Regression Trees (GBRT) \n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "def Grad_Boost_regression(train_x, train_y, test_x, test_y,X_test,subpopulation, X_train, Y_train):\n",
    "   \n",
    "    # Tune parameters to find optimal ones\n",
    "    n_estimators = [100, 150, 300]\n",
    "    loss = ['ls','lad','huber']\n",
    "    grid_parameters = {'n_estimators': n_estimators}\n",
    "  #  regressor = RandomizedSearchCV(GradientBoostingRegressor(learning_rate=0.1), grid_parameters, scoring='neg_mean_squared_error', \n",
    " #                                  cv=3)\n",
    "    \n",
    "    regressor =  GradientBoostingRegressor(n_estimators=500, learning_rate=0.1,\n",
    "                                            max_depth=1, random_state=0, loss='huber')\n",
    "    regressor.fit(train_x, train_y)\n",
    "    y_pred = regressor.predict(test_x)\n",
    "    \n",
    "    \n",
    "    if (subpopulation == 'confirmed'):\n",
    "         prediction_models_confirmed['Grad_Tree_Boost'] = mean_absolute_error(y_pred, test_y)\n",
    "    elif (subpopulation == 'deaths'):\n",
    "        prediction_models_deaths['Grad_Tree_Boost'] = mean_absolute_error(y_pred, test_y)\n",
    "    else :\n",
    "        prediction_models_recoveries['Grad_Tree_Boost'] = mean_absolute_error(y_pred, test_y)\n",
    "    \n",
    "    regressor.fit(X_train, Y_train)\n",
    "    predictions = regressor.predict(X_test)\n",
    "    \n",
    "    return(predictions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if a timeseries is stationary\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "def test_stationarity(timeseries):\n",
    "    \n",
    "    #Determing rolling statistics\n",
    "    rolmean = timeseries.rolling(12).mean()     \n",
    "    rolstd = timeseries.rolling(12).std()\n",
    "    \n",
    "    #Perform Dickey-Fuller test:\n",
    "    dftest = adfuller(timeseries, autolag='AIC')\n",
    "    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n",
    "    for key,value in dftest[4].items():\n",
    "        dfoutput['Critical Value (%s)'%key] = value\n",
    "    return dfoutput\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_with_arima(timeseries,n_days_ahead):\n",
    "    \n",
    "    #find the optimal d \n",
    "    diff=timeseries-timeseries.shift(1)\n",
    "    for d in range(1,10):\n",
    "        if (test_stationarity(diff.dropna())['p-value']<0.1):\n",
    "            break\n",
    "        else: \n",
    "            d=d+1 \n",
    "            diff=diff-diff.shift(1)\n",
    "            \n",
    "    #use the arima model to make predictions, use original timeseries with optimal d:\n",
    "    model = pm.auto_arima(timeseries, start_p=0, start_q=0,\n",
    "                             max_p=4, max_q=4,\n",
    "                              seasonal=False,\n",
    "                             d=d, trace=True,\n",
    "                             error_action='ignore',  # don't want to know if an order does not work\n",
    "                             suppress_warnings=True,  # don't want convergence warnings\n",
    "                             stepwise=False)\n",
    "    #print(model)\n",
    "    forecasts, conf_int =model.predict(n_days_ahead,return_conf_int=True ,alpha=0.05)\n",
    "    \n",
    "    return forecasts , conf_int  # returns a tuple, array of forecasts and all conf int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Arima_Analysis(region,pred_days_ahead):\n",
    "   #create a dataframe for timeseries analysis\n",
    "    date_rng = pd.date_range(start=colnames[4], end=colnames[-1], freq='D') #creates the days\n",
    "    df = pd.DataFrame(date_rng, columns=['date'])\n",
    "    df['cases']=np.transpose(region) #this is a dataframe with dates and cases.\n",
    "    df = df.set_index('date')\n",
    "    df=df[df['cases'] != 0] #remove zeroes, they do not help for analysis. \n",
    "    if (len(df)>1):\n",
    "        if(df['cases'][-1]-df['cases'][0]>5):\n",
    "            pred_ts,conf_int=pred_with_arima(df['cases'],pred_days_ahead) #this is an array converted to a list\n",
    "        else:\n",
    "            pred_ts=[df['cases'][-1]+1]*pred_days_ahead\n",
    "            conf_int=[np.array([df['cases'][-1],df['cases'][-1]+2])]*pred_days_ahead\n",
    "    else:\n",
    "        pred_ts=np.zeros(pred_days_ahead)\n",
    "        conf_int=[np.zeros(pred_days_ahead)] * pred_days_ahead\n",
    "    return pred_ts, conf_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "def subpopulation_Analysis(cases,country,province, all_days,predictions_ahead,subpopulation, pred_days_ahead):\n",
    "    \n",
    "    pred  = list()\n",
    "    if pd.isnull(province):\n",
    "        region = cases.loc[(cases['Country/Region'] == country) & (pd.isnull(cases['Province/State']))]\n",
    "    else :\n",
    "        region = cases.loc[(cases['Country/Region'] == country) & (cases['Province/State'] == province)]\n",
    "    print(region)\n",
    "    \n",
    "    reg =  np.array(region.loc[:, colnames[4]:colnames[-1]])\n",
    "    region =  np.array(region.loc[:, colnames[4]:colnames[-1]]).reshape(-1, 1)\n",
    "        \n",
    "    #train_x, test_x, train_y, test_y = model_selection.train_test_split(all_days,region,test_size = 0.04,random_state = 42,shuffle=False)\n",
    "    \n",
    "    #pred_svm =  SVM_regression(train_x, train_y.ravel(), test_x, test_y, predictions_ahead,subpopulation,all_days,region.ravel())\n",
    "    #pred.append(pred_svm)\n",
    "    \n",
    "    #TODO: a for loop\n",
    "    daily_increase_threshold1=np.absolute((reg[-1][-1]-reg[-1][-2])/reg[-1][-2])*100\n",
    "    daily_increase_threshold2=np.absolute((reg[-1][-2]-reg[-1][-3])/reg[-1][-3])*100\n",
    "    daily_increase_threshold3=np.absolute((reg[-1][-3]-reg[-1][-4])/reg[-1][-4])*100\n",
    "    daily_increase_threshold4=np.absolute((reg[-1][-4]-reg[-1][-5])/reg[-1][-5])*100\n",
    "    daily_increase_bound=1000\n",
    "    daily_increase_threshold = max(daily_increase_threshold1,daily_increase_threshold2,daily_increase_threshold3,daily_increase_threshold4)\n",
    "    \n",
    "    if (daily_increase_threshold>daily_increase_bound):\n",
    "        best_pred_ahead = 0  \n",
    "        region = region\n",
    "        best_pred = 0\n",
    "        best_conf_int = np.zeros(2)\n",
    "        reject_country = 1\n",
    "        return(best_pred_ahead, region, best_pred, best_conf_int, reject_country)\n",
    "     \n",
    "    \n",
    "    pred_arima, conf_int=Arima_Analysis(reg,pred_days_ahead)\n",
    "    #pred.append(pred_svm)\n",
    "    #pred_RF = RF_regression(train_x, train_y.ravel(), test_x, test_y, predictions_ahead,subpopulation,all_days,region.ravel())\n",
    "    #pred.append(pred_RF)\n",
    "\n",
    "    \n",
    "   # pred_gb =  Grad_Boost_regression(train_x, train_y.ravel(), test_x, test_y, predictions_ahead,subpopulation,all_days,region.ravel())\n",
    "   # pred.append(pred_gb)\n",
    "\n",
    "\n",
    "    if (subpopulation == 'confirmed'): \n",
    "        if (len(pred_arima)==0):\n",
    "            min_idx, (min_key, min_val) = min(enumerate(prediction_models_confirmed.items()), key=lambda x: x[1][1])\n",
    "            best_pred = pred[min_idx]\n",
    "            conf_int=np.zeros(2)\n",
    "        else:\n",
    "            best_pred=pred_arima\n",
    "            conf_int=conf_int\n",
    "    elif (subpopulation == 'deaths'):\n",
    "        if (len(pred_arima)==0):\n",
    "            min_idx, (min_key, min_val) = min(enumerate(prediction_models_deaths.items()), key=lambda x: x[1][1])\n",
    "            best_pred = pred[min_idx]\n",
    "            conf_int=np.zeros(2)\n",
    "        else:\n",
    "            best_pred=pred_arima\n",
    "            conf_int=conf_int\n",
    "    else :\n",
    "        if (len(pred_arima)==0):\n",
    "            min_idx, (min_key, min_val) = min(enumerate(prediction_models_recoveries.items()), key=lambda x: x[1][1])\n",
    "            best_pred = pred[min_idx]\n",
    "            conf_int=np.zeros(2)\n",
    "        else:\n",
    "            best_pred=pred_arima\n",
    "            conf_int=conf_int\n",
    "        \n",
    "\n",
    "    best_pred_ahead = best_pred[-1]\n",
    "    best_conf_int=conf_int[-1]\n",
    "   \n",
    "    best_conf_int[0]=max(reg[-1][-1], best_conf_int[0])\n",
    "    if (best_conf_int[0]>best_conf_int[1]):\n",
    "        best_conf_int[1]=2*reg[-1][-1]\n",
    "\n",
    "    if(best_pred_ahead<reg[-1][-1]):\n",
    "        best_pred_ahead= reg[-1][-1]+pred_days_ahead\n",
    "    \n",
    "    reject_country = 0\n",
    "    \n",
    "    return best_pred_ahead, region, best_pred, best_conf_int, reject_country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_file = str(2)+\"day_prediction_\" +  date.today().strftime('%Y-%m-%d') + \".csv\"\n",
    "#pred_file = str(7)+\"day_prediction_\" + date.today().strftime('%Y-%m-%d') + \".csv\"\n",
    "#pred_file = str(30)+\"day_prediction_\" + date.today().strftime('%Y-%m-%d') + \".csv\"\n",
    "pred_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "columns = ['Province/State','Country','Target/Date','N','low95N','high95N',\n",
    "          'R','low95R','high95R','D','low95D','high95D','T','low95T','high95T',\n",
    "           'M','low95M','high95M','C','low95C','high95C']\n",
    "\n",
    "            \n",
    "\n",
    "k = 0\n",
    "for co in range(len(countries)):\n",
    "    \n",
    "    ignore_recoveries = 0    \n",
    "    \n",
    "    total_predictions = pd.DataFrame(columns = columns)\n",
    "    \n",
    "    k = k + 1\n",
    "       \n",
    "    best_pred_confirmed, region_con, best_pred_con, conf_int_con, reject_country = subpopulation_Analysis(confirmed_cases,countries[co],province[co],\n",
    "                                                 all_days,predictions_ahead,\"confirmed\",pred_days_ahead)\n",
    "    \n",
    "    if (reject_country==1):\n",
    "        print('rejected_conf')\n",
    "        continue\n",
    "        \n",
    "    best_pred_deaths, region_d, best_pred_d, conf_int_d, reject_country = subpopulation_Analysis(deaths_cases,countries[co],province[co],\n",
    "                                              all_days,predictions_ahead,\"deaths\",pred_days_ahead)\n",
    "    if (reject_country==1):\n",
    "        print('rejected_d')\n",
    "        continue\n",
    "        \n",
    "    if ((countries[co] == 'US' or countries[co] == 'Canada' ) & (pd.notnull(province[co]))):\n",
    "        ignore_recoveries=1   \n",
    "    else:\n",
    "        best_pred_recoveries, region_r, best_pred_r, conf_int_r, reject_country = subpopulation_Analysis(recoveries_cases,countries[co],province[co],\n",
    "                                                  all_days,predictions_ahead,\"recoveries\",pred_days_ahead)\n",
    "    \n",
    "    if (reject_country==1):\n",
    "        print('rejected_r')\n",
    "        continue\n",
    "    \n",
    "    # Mortality rate\n",
    "    if (conf_int_con[0]==0):\n",
    "        mort_pred=0\n",
    "        mort_pred_low=0\n",
    "        mort_pred_up=0\n",
    "    else:\n",
    "        mort_pred  = best_pred_deaths/best_pred_confirmed\n",
    "        mort_pred_low= conf_int_d[0]/conf_int_con[1]\n",
    "        mort_pred_up=conf_int_d[1]/conf_int_con[0]\n",
    "    \n",
    "    #fix province\n",
    "    province_name=''\n",
    "    if (pd.notnull(province[co])) :\n",
    "        province_name=province[co]\n",
    "    \n",
    "    if (ignore_recoveries==0):\n",
    "        R_value=int(best_pred_recoveries) \n",
    "        low_R=int(conf_int_r[0])\n",
    "        high_R=int(conf_int_r[1])\n",
    "    else:\n",
    "        R_value=''\n",
    "        low_R=''\n",
    "        high_R=''\n",
    "        \n",
    "    #Critical Cases:\n",
    "    #Assume that 5% of all cases are critical and need hospitalization:\n",
    "    serious_percentage=0.05\n",
    "    critical=serious_percentage*best_pred_confirmed\n",
    "    low_critical=serious_percentage*conf_int_con[0]\n",
    "    high_critical=serious_percentage*conf_int_con[1]\n",
    "    \n",
    "    total_predictions = total_predictions.append({'Province/State': province_name,\n",
    "                                                'Country': countries[co],\n",
    "                                                'Target/Date': predictions_ahead_dates[-1].strftime('%Y-%m-%d'), \n",
    "                                                'N': int(best_pred_confirmed) ,\n",
    "                                                'low95N':int(conf_int_con[0]),\n",
    "                                                'high95N': int(conf_int_con[1]),\n",
    "                                                'R': R_value ,\n",
    "                                                'low95R' : low_R,\n",
    "                                                'high95R' : high_R,\n",
    "                                                'D': int(best_pred_deaths) ,\n",
    "                                                'low95D' : int(conf_int_d[0]),\n",
    "                                                'high95D': int(conf_int_d[1]),\n",
    "                                                'T': '',\n",
    "                                                'low95T' : '' ,\n",
    "                                                'high95T' : '',\n",
    "                                                'M': mort_pred,\n",
    "                                                'low95M': mort_pred_low,\n",
    "                                                'high95M': mort_pred_up ,\n",
    "                                                'C': int(critical) ,\n",
    "                                                'low95C':  int(low_critical) ,\n",
    "                                                'high95C': int(high_critical) },ignore_index = True)\n",
    "    \n",
    "    if (k==1):\n",
    "        header = True\n",
    "    else:\n",
    "        header = False\n",
    "    \n",
    "    total_predictions.to_csv(pred_file, sep=',',index = False,  mode='a', header = header)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
